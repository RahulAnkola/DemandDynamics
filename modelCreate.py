# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uLzaR53nFoj2LZM0oB6s9UkuBpl3PvCf
"""

# -*- coding: utf-8 -*-
"""
Created on Thu Mar 18 12:28:47 2021

@author: rhaul
"""
import numpy as np
import pandas as pd
from scipy.stats import describe

import warnings

warnings.simplefilter('ignore')
import matplotlib.pyplot as plt

import seaborn as sns
sns.set()
df_train = pd.read_csv('train.csv')


df_train['date'] = pd.to_datetime(df_train['date'])
df_train.index = pd.DatetimeIndex(df_train['date'])
df_train.drop('date', axis=1, inplace=True)

from itertools import product, starmap


def storeitems():
    return product(range(1,51), range(1,11))


def storeitems_column_names():
    return list(starmap(lambda i,s: f'item_{i}_store_{s}_sales', storeitems()))


def sales_by_storeitem(df):
    ret = pd.DataFrame(index=df.index.unique())
    for i, s in storeitems():
        ret[f'item_{i}_store_{s}_sales'] = df[(df['item'] == i) & (df['store'] == s)]['sales'].values
    return ret

df_train = sales_by_storeitem(df_train)

# load data
df_test = pd.read_csv('test.csv')
# strings to dates
df_test['date'] = pd.to_datetime(df_test['date'])
df_test.index = pd.DatetimeIndex(df_test['date'])
df_test.drop('date', axis=1, inplace=True)

# mock sales to use same transformations as in df_train
df_test['sales'] = np.zeros(df_test.shape[0])
df_test = sales_by_storeitem(df_test)

# make sure all column names are the same and in the same order
col_names = list(zip(df_test.columns, df_train.columns))
for cn in col_names:
    assert cn[0] == cn[1]

df_test['is_test'] = np.repeat(True, df_test.shape[0])
df_train['is_test'] = np.repeat(False, df_train.shape[0])
df_total = pd.concat([df_train, df_test])

weekday_df = pd.get_dummies(df_total.index.weekday, prefix='weekday')
weekday_df.index = df_total.index

month_df = pd.get_dummies(df_total.index.month, prefix='month')
month_df.index =  df_total.index

df_total = pd.concat([weekday_df, month_df, df_total], axis=1)

from sklearn.preprocessing import MinMaxScaler
cols_to_scale = [col for col in df_total.columns if 'weekday' not in col and 'month' not in col and 'is_' not in col]

scaler = MinMaxScaler(feature_range=(0,1))
scaled_cols = scaler.fit_transform(df_total[cols_to_scale])
df_total[cols_to_scale] = scaled_cols

df_train = df_total[df_total['is_test'] == False].drop('is_test', axis=1)
df_test = df_total[df_total['is_test'] == True].drop('is_test', axis=1)

def to_sequences(dataset, seq_size=1):
    x = []
    y = []

    for i in range(len(dataset)-seq_size):
        window = dataset.iloc[i:(i+seq_size), :]
        x.append(window)
        y.append(dataset.iloc[i+seq_size, 19:])

    return np.array(x),np.array(y)

seq_size = 3
X, y = to_sequences(df_train, seq_size)

print("Shape of training set: {}".format(X.shape))
inputshape = (X.shape[1], X.shape[2])
print(inputshape)

from keras.callbacks import EarlyStopping
from keras.models import Sequential
from keras.layers import LSTM, Flatten,Dropout,Dense


model = Sequential()
model.add(LSTM(128, activation='relu',input_shape=inputshape, return_sequences=True))
model.add(Dropout(0.1))
model.add(LSTM(64, activation='tanh', return_sequences=True))
model.add(Dropout(0.1))
model.add(LSTM(32, activation='tanh', return_sequences=False))
model.add(Dense(500))


model.compile(optimizer='adam', loss = 'mse', metrics = ['accuracy'])
model.summary()

X = np.asarray(X).astype(np.int)
y = np.asarray(y).astype(np.int)
print(X.shape, y.shape)
model.fit(X, y, verbose=1, epochs = 2,batch_size = 1,shuffle = False)


temp = df_train.iloc[-seq_size:,:]
temp = pd.concat([temp,df_test],axis =0)

for i in range(0,90):
    temp_list = []
    temp_var = temp.iloc[i:(i+seq_size),:]
    temp_list.append(temp_var)
    temp_array = np.array(temp_list)
    temp_array = temp_array.reshape(1,seq_size,519)

    temp_array = np.asarray(temp_array).astype(np.int)


    prediction = model.predict(temp_array)
    temp.iloc[(i+seq_size):(i+seq_size+1),19:] = prediction.flatten().tolist()

temp = temp.iloc[seq_size:,:]
temp[cols_to_scale] = scaler.inverse_transform(temp[cols_to_scale])

result = np.zeros(0,dtype=np.int)

for i, s in storeitems():
    col_name = f'item_{i}_store_{s}_sales'
    result = np.concatenate((result,temp[col_name].values))
result = result.round()
result = pd.DataFrame(result, columns=['sales'])
result.index.name = 'id'
result.head()
result.to_csv('submission1.csv')

model.save(r"D:\Coding\DemandDynamics\ddmodel1.h5")
